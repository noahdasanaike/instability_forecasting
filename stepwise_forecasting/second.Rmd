---
title: "Neural"
output: html_notebook
---

```{r one}
library(tidyverse)
library(WDI)
library(janitor)
library(countrycode)
library(readxl)
library(MASS)
library(dataPreparation)
library(glmnet)
library(DMwR)
library(splitTools)
library(ranger)
library(Metrics)
library(randomForest)
library(party)
```

```{r conflict}
conflict_data <- read_csv("conflict_data.csv")

full_conflict <- tibble(country_code = unique(conflict_data$country_code)) %>% 
  slice(rep(1:n(), each = 31)) %>%
  group_by(country_code) %>%
  mutate(year = row_number() + 1988) %>%
  merge(conflict_data, by = c("country_code", "year"), all.x = TRUE) %>%
  rowwise() %>%
  mutate(conflict = mean(c(acled_total, ucdp_total, gdelt_total), na.rm = TRUE)) %>%
  pivot_wider(names_from = event_type, values_from = conflict) %>%
  dplyr::select(-c(acled_total, ucdp_total, gdelt_total, `NA`)) %>%
  drop_na(country_code) %>%
  rename(protest = `14`, assault = `18`, fight = `19`) %>% 
  group_by(country_code, year) %>% 
  summarise_all(funs(first(na.omit(.))))

full_conflict[is.na(full_conflict)] <- 0
```

```{r merge}
pca_data <- full_conflict[3:5]

pcr_matrix <- as.matrix(pca_data)

x <- NULL

for (i in 2:15){
  k <- kmeans(pca_data, i, nstart = 25, iter.max = 30)["tot.withinss"][[1]]
  x <- rbind(x, c(i, k))
}

x <- x %>%
  as.tibble()

ggplot(data = x, aes(x = V1, y = V2)) +
  geom_point()

cluster <- kmeans(pca_data, 5, nstart = 25)

pca <- prcomp(pca_data)

test <- tibble(country_name = full_conflict$country_code,
               year = full_conflict$year,
               pca1 =  pca$x[,1],
               pca2 = pca$x[,2],
               cluster = cluster$cluster)

test %>%
  filter(year == 2016) %>%
  mutate(cluster = as.factor(cluster)) %>%
  ggplot(aes(x = pca1, y = pca2, group = cluster, color = cluster)) +
  geom_text(aes(label = country_name))
```

```{r indicators, warning = FALSE, message = FALSE}
peace <- read_xls("peace_months.xls") %>%
  dplyr::select(year, country, peaceyears) %>%
  mutate(iso3 = countrycode(country, origin = "country.name", destination = "iso3c")) %>%
  drop_na(iso3) %>%
  mutate(year_ahead = ifelse(lead(peaceyears) > 0, 0, 1)) %>%
  mutate(year_ahead = ifelse(is.na(lead(peaceyears)), 1, year_ahead)) %>%
  mutate(current_year = ifelse(peaceyears > 0, 0, 1)) %>%
  mutate(current_year = ifelse(is.na(peaceyears), 1, current_year)) %>%
  dplyr::select(year, year_ahead, iso3, current_year) 

indicators <- WDIsearch()

# new_cache = WDIcache()
# dat = WDI(cache = new_cache, 
#           indicator = c(unlist(indicators[, 1])),
#           country = "all", start = 1989, end = 2019)

test_for_merge <- test %>%
  rename(iso3 = country_name) %>%
  dplyr::select(iso3, cluster, year)

dat <- readRDS("wdi_data.RDS")

dat <- dat %>%
  clean_names() %>% 
  mutate(iso3 = countrycode(iso2c, origin = "iso2c", destination = "iso3c")) %>%
  dplyr::select(-c(country, iso2c))

merged <- merge(dat, peace, by = c("iso3", "year")) %>%
  drop_na(iso3) %>%
  merge(test_for_merge, by = c("iso3", "year"))

nas <- merged %>% keep(~all(is.na(.x))) %>% names

merged <- merged[ , -which(names(merged) %in% c(unlist(nas)))]

merged <- merged %>% 
  drop_na(year_ahead) %>%
  group_by(year, cluster) %>% 
  mutate_each(funs(replace(., which(is.na(.)),
                           mean(., na.rm=TRUE)))) %>%
  group_by(iso3) %>%
  mutate_each(funs(replace(., which(is.nan(.)),
                           mean(., na.rm=TRUE))))

merge_filter <- merged 

no_na <- merge_filter

# bijections are from which_are_bijection(no_na)
no_na <- no_na[-c(6, 14, 77, 78, 79, 111)]

countries <- unique(merge_filter$iso3)

no_na <- no_na %>%
  rowwise() %>%
  mutate(iso3 = match(iso3, countries),
         year = as.numeric(year)) %>%
  arrange(year)

#################
```

randomly sampled elastic net, highest "accuracy" but only because it ignores 1s...

```{r best accuracy}
train_data <- sample(1:nrow(no_na), (nrow(no_na) * .8))
test_data <- which(!1:nrow(no_na) %in% train_data)

x <- no_na[, 1:143]

y <- merge_filter$year_ahead

foldid <- sample(1:10, size = length( y[train_data]), replace = TRUE)

mod <- cv.glmnet(as.matrix(x[train_data, ]), y[train_data], alpha = 0.9, family = "binomial")

lambda.min <- mod$lambda.min

yhat <- predict(mod, newx = as.matrix(x[test_data, ]),
                      s = lambda.min,
                      type = "response")

pred <- yhat %>% tibble() %>% rename(pred = ".")

index = min(pred)
best_cutoff <- 0
best_accuracy <- 0

while (index < max(pred))
{
  cutoff <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))

  accuracy <- mean(cutoff$pred == y[test_data])

  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }

  index = index + 0.01
}


comparison <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > best_cutoff, 1, 0))

comparison$actual <- y[test_data]

mean(comparison$actual == comparison$pred)
```

random forest

```{r randomforest}
train <- no_na %>%
  ungroup() %>%
  filter(year < 2016) %>%
  dplyr::select(-c(cluster, year))

test <- no_na %>%
  ungroup() %>%
  filter(year == 2016) %>%
  dplyr::select(-c(cluster, year))

test_more <- test %>%
  dplyr::select(-c(year_ahead))

folds <- create_timefolds(train$year_ahead, k = 5)

valid_mtry <- numeric(ncol(train) - 1)

for (i in seq_along(valid_mtry)) {
  cv_mtry <- numeric()
  for (fold in folds) {
    fit <- ranger(year_ahead ~ ., data = train[fold$insample, ], mtry = i)
    cv_mtry <- c(cv_mtry, 
                 rmse(train[fold$outsample, "year_ahead"]$year_ahead, 
                      predict(fit, train[fold$outsample, ])$predictions))
  }
  print(i)
  print(mean(cv_mtry))
  valid_mtry[i] <- mean(cv_mtry)
}

best_mtry <- 0.2510958

final_fit <- ranger(year_ahead ~ ., data = train, mtry = 102, importance = "impurity")
pred <- predict(final_fit, test_more)$predictions

index = min(pred)
best_cutoff <- 0
best_accuracy <- 0

while (index < 1)
{
  cutoff <- pred %>%
  tibble() %>%
  rename(pred = ".") %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))

  accuracy <- mean(cutoff$pred == test$year_ahead)

  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }

  index = index + 0.01
}

predictions <- pred %>%
  tibble() %>%
  rename(pred = ".") %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > best_cutoff, 1, 0))

predictions$actual <- test$year_ahead

```

This is a near-LASSO elastic net that over-samples cases of violence in order to account for imbalance

```{r over_sampling}
x <- no_na %>%
  mutate(year_ahead = as.factor(year_ahead)) %>%
  as.data.frame()
 
train_x <- SMOTE(year_ahead~., subset(x, year < 2016), perc.over = 800, perc.under = 100)
 
train_y <- train_x$year_ahead
 
train_x <- train_x %>%
  dplyr::select(-c(year, year_ahead, cluster))
 
mod <- cv.glmnet(as.matrix(train_x), train_y, alpha = 0.9, family = "binomial")
lambda.min <- mod$lambda.min
 
 
test_x <- x %>%
  filter(year == 2016)
 
test_y <- test_x$year_ahead
 
test_x <- test_x %>%
  dplyr::select(-c(year, year_ahead, cluster))
 
 
yhat <- predict(mod, newx = as.matrix(test_x),
                      s = lambda.min,
                      type = "response")
 
pred <- yhat %>% tibble() %>% rename(pred = ".")
 
index = min(pred)
 
best_cutoff <- 0
best_accuracy <- 0
 
while (index < 2)
{
  cutoff <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))
 
  accuracy <- mean(cutoff$pred == test_y)
 
  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }
 
  index = index + 0.01
}
 
comparison <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > 0.99, 1, 0))
 
comparison$actual <- y[test_data]
 
mean(comparison$actual == comparison$pred)
```
