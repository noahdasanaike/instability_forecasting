---
title: "Neural"
output: html_notebook
---

```{r one, warning=FALSE}
library(tidyverse)
library(WDI)
library(janitor)
library(countrycode)
library(readxl)
library(MASS)
library(dataPreparation)
library(glmnet)
library(rworldmap)

demean.mat <- function(xmat) {
  apply(xmat, 2, function(z) z - mean(z))
}

library(DMwR)
#library(splitTools)
library(ranger)
library(Metrics)
library(randomForest)
library(party)
```

```{r conflict}
conflict_data <- read_csv("conflict_data.csv")

full_conflict <- tibble(country_code = unique(conflict_data$country_code)) %>% 
  slice(rep(1:n(), each = 31)) %>%
  group_by(country_code) %>%
  mutate(year = row_number() + 1988) %>%
  merge(conflict_data, by = c("country_code", "year"), all.x = TRUE) %>%
  rowwise() %>%
  mutate(conflict = mean(c(acled_total, ucdp_total, gdelt_total), na.rm = TRUE)) %>%
  pivot_wider(names_from = event_type, values_from = conflict) %>%
  dplyr::select(-c(acled_total, ucdp_total, gdelt_total, `NA`)) %>%
  drop_na(country_code) %>%
  rename(protest = `14`, assault = `18`, fight = `19`) %>% 
  group_by(country_code, year) %>% 
  summarise_all(funs(first(na.omit(.))))

full_conflict[is.na(full_conflict)] <- 0
```

```{r merge}
pca_data <- full_conflict[3:5]

pcr_matrix <- as.matrix(pca_data)

x <- NULL

for (i in 2:15){
  k <- kmeans(pca_data, i, nstart = 25, iter.max = 30)["tot.withinss"][[1]]
  x <- rbind(x, c(i, k))
}

x <- x %>%
  as.tibble()

ggplot(data = x, aes(x = V1, y = V2)) +
  geom_point()

cluster <- kmeans(pca_data, 5, nstart = 25)

pca <- prcomp(pca_data)

test <- tibble(country_name = full_conflict$country_code,
               year = full_conflict$year,
               pca1 =  pca$x[,1],
               pca2 = pca$x[,2],
               cluster = cluster$cluster)

test %>%
  filter(year == 2016) %>%
  mutate(cluster = as.factor(cluster)) %>%
  ggplot(aes(x = pca1, y = pca2, group = cluster, color = cluster)) +
  geom_text(aes(label = country_name))
```

```{r indicators, warning = FALSE, message = FALSE}
peace <- read_xls("peace_months.xls") %>%
  dplyr::select(year, country, peaceyears) %>%
  mutate(iso3 = countrycode(country, origin = "country.name", destination = "iso3c")) %>%
  drop_na(iso3) %>%
  mutate(year_ahead = ifelse(lead(peaceyears) > 0, 0, 1)) %>%
  mutate(year_ahead = ifelse(is.na(lead(peaceyears)), 1, year_ahead)) %>%
  mutate(current_year = ifelse(peaceyears > 0, 0, 1)) %>%
  mutate(current_year = ifelse(is.na(peaceyears), 1, current_year)) %>%
  dplyr::select(year, year_ahead, iso3, current_year, peaceyears) 

indicators <- WDIsearch()

# new_cache = WDIcache()
# dat = WDI(cache = new_cache, 
#           indicator = c(unlist(indicators[, 1])),
#           country = "all", start = 1989, end = 2019)

test_for_merge <- test %>%
  rename(iso3 = country_name) %>%
  dplyr::select(iso3, cluster, year)

dat <- readRDS("wdi_data.RDS")

dat <- dat %>%
  clean_names() %>% 
  mutate(iso3 = countrycode(iso2c, origin = "iso2c", destination = "iso3c")) %>%
  dplyr::select(-c(country, iso2c))

merged <- merge(dat, peace, by = c("iso3", "year")) %>%
  drop_na(iso3) %>%
  merge(test_for_merge, by = c("iso3", "year"))

nas <- merged %>% keep(~all(is.na(.x))) %>% names

merged <- merged[ , -which(names(merged) %in% c(unlist(nas)))]

merged <- merged %>% 
  drop_na(year_ahead) %>%
  group_by(year, cluster) %>% 
  mutate_each(funs(replace(., which(is.na(.)),
                           mean(., na.rm=TRUE)))) %>%
  group_by(iso3) %>%
  mutate_each(funs(replace(., which(is.nan(.)),
                           mean(., na.rm=TRUE))))

merge_filter <- merged 

no_na <- merge_filter

# bijections are from which_are_bijection(no_na)
no_na <- no_na[-c(6, 14, 77, 78, 79, 111)]

countries <- unique(merge_filter$iso3)

no_na <- no_na %>%
  rowwise() %>%
  mutate(iso3 = match(iso3, countries),
         year = as.numeric(year)) %>%
  arrange(year)

#################
```

randomly sampled elastic net

```{r best accuracy}
train_data <- sample(1:nrow(no_na), (nrow(no_na) * .8))
test_data <- which(!1:nrow(no_na) %in% train_data)

x <- no_na %>%
  dplyr::select(-c(cluster, year_ahead))

y <- no_na$year_ahead

foldid <- sample(1:10, size = length( y[train_data]), replace = TRUE)

mod <- cv.glmnet(as.matrix(x[train_data, ]), y[train_data], alpha = 0.9, family = "binomial")

lambda.min <- mod$lambda.min

yhat <- predict(mod, newx = as.matrix(x[test_data, ]),
                      s = lambda.min,
                      type = "response")

pred <- yhat %>% tibble() %>% rename(pred = ".")

index = min(pred)
best_cutoff <- 0
best_accuracy <- 0

while (index < max(pred))
{
  cutoff <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))

  accuracy <- mean(cutoff$pred == y[test_data])

  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }

  index = index + 0.01
}


comparison <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > best_cutoff, 1, 0))

comparison$actual <- y[test_data]

mean(comparison$actual == comparison$pred)

f1score(comparison$pred, comparison$actual)

coef(mod)
```

```{r all data up to 2013 as train}
#train_data <- sample(1:nrow(no_na), (nrow(no_na) * .8))
#test_data <- which(!1:nrow(no_na) %in% train_data)

train_data <- which(no_na$year<2014)
test_data <- which(no_na$year>=2014)

x <- no_na %>%
  dplyr::select(-c(cluster, year_ahead))

y <- no_na$year_ahead

foldid <- sample(1:10, size = length( y[train_data]), replace = TRUE)

mod <- cv.glmnet(as.matrix(x[train_data, ]), y[train_data], alpha = 0.9, family = "binomial")

lambda.min <- mod$lambda.min

yhat <- predict(mod, newx = as.matrix(x[test_data, ]),
                      s = lambda.min,
                      type = "response")

pred <- yhat %>% tibble() %>% rename(pred = ".")

index = min(pred)
best_cutoff <- 0
best_accuracy <- 0

while (index < max(pred))
{
  cutoff <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))

  accuracy <- mean(cutoff$pred == y[test_data])
  accuracy <- f1score(cutoff$pred, y[test_data])$AUC

  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }

  index = index + 0.01
}


comparison <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > best_cutoff, 1, 0))

pred_probs <- pred

comparison$actual <- y[test_data]

mean(comparison$actual == comparison$pred)

f1score(comparison$pred, comparison$actual)

coef(mod)
```



random forest

```{r randomforest}
train <- no_na %>%
  ungroup() %>%
  filter(year < 2016) %>%
  dplyr::select(-c(cluster, year))

test <- no_na %>%
  ungroup() %>%
  filter(year == 2016) %>%
  dplyr::select(-c(cluster, year))

test_more <- test %>%
  dplyr::select(-c(year_ahead))

folds <- create_timefolds(train$year_ahead, k = 5)

valid_mtry <- numeric(ncol(train) - 1)

# for (i in seq_along(valid_mtry)) {
#   cv_mtry <- numeric()
#   for (fold in folds) {
#     fit <- ranger(year_ahead ~ ., data = train[fold$insample, ], mtry = i)
#     cv_mtry <- c(cv_mtry, 
#                  rmse(train[fold$outsample, "year_ahead"]$year_ahead, 
#                       predict(fit, train[fold$outsample, ])$predictions))
#   }
#   print(i)
#   print(mean(cv_mtry))
#   valid_mtry[i] <- mean(cv_mtry)
# }

best_mtry <- 0.2510958

final_fit <- ranger(year_ahead ~ ., data = train, mtry = 102, importance = "impurity")
pred <- predict(final_fit, test_more)$predictions

index = min(pred)
best_cutoff <- 0
best_accuracy <- 0

while (index < 1)
{
  cutoff <- pred %>%
  tibble() %>%
  rename(pred = ".") %>%
  rowwise() %>%

  mutate(pred = ifelse(pred > index, 1, 0))

  accuracy <- mean(cutoff$pred == test$year_ahead)

  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }

  index = index + 0.01
}

predictions <- pred %>%
  tibble() %>%
  rename(pred = ".") %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > best_cutoff, 1, 0))

predictions$actual <- test$year_ahead

```


```{r heatmaps}

f1score <- function(predicted, y_true) {
  true_p <- sum(predicted==y_true & predicted==1)
  true_n <- sum(predicted==y_true & predicted==0)
  false_p <- sum(predicted==1 & y_true==0)
  false_n <- sum(predicted==0 & y_true==1)
  accuracy <- mean(predicted==y_true)
  precision <- true_p/(true_p+false_p)
  recall <- true_p/(true_p+false_n)
  f1 <- 2/(1/precision + 1/recall)
  auc <- auc(y_true, predicted)
  return(list(Accuracy=accuracy, Precision=precision, Recall=recall, F1=f1, AUC=auc))
}



renderHeatmap <- function(data, year, coltoplot) {
    mapped_data <- data[data$year==year,]
    mapped_data <- joinCountryData2Map(mapped_data, joinCode="ISO3", nameJoinColumn="iso3")
    par(mai=c(1,0,0.5,0),xaxs="i",yaxs="i")
    mapCountryData(mapped_data, nameColumnToPlot = coltoplot, catMethod="fixedWidth",
                   mapTitle=paste("Difference in Predicted vs Actual Conflict by Country in ", year, sep=""),
                   missingCountryCol="white", colourPalette="diverging") #brewer.pal(10, "YlOrRd"))
}


country_preds <- comparison
names(country_preds)[1] = "prediction"
country_preds["iso3"] = arrange(merge_filter, year)$iso3[test_data]
country_preds["year"] = no_na$year[test_data]
renderHeatmap(country_preds, 2015, "prediction")

pred_probs_plot <- pred_probs
names(pred_probs_plot)[1] = "prediction"
pred_probs_plot["iso3"] = arrange(merge_filter, year)$iso3[test_data]
pred_probs_plot["year"] = no_na$year[test_data]
renderHeatmap(pred_probs_plot, 2016, "prediction")

delta <- country_preds
delta["diff"] = delta$prediction-delta$actual
renderHeatmap(delta, 2014, "diff")

delta <- pred_probs_plot
delta["diff"] = delta$prediction-country_preds$actual
renderHeatmap(delta, 2016, "diff")

year_filter <- country_preds[country_preds$year==2016,]
f1score(year_filter$prediction, year_filter$actual)
```


This is a near-LASSO elastic net that over-samples cases of violence in order to account for imbalance

```{r over_sampling}
x <- no_na %>%
  mutate(year_ahead = as.factor(year_ahead)) %>%
  as.data.frame()
 
train_x <- SMOTE(year_ahead~., subset(x, year < 2016), perc.over = 800, perc.under = 100)
 
train_y <- train_x$year_ahead
 
train_x <- train_x %>%
  dplyr::select(-c(year, year_ahead, cluster))
 
mod <- cv.glmnet(as.matrix(train_x), train_y, alpha = 0.9, family = "binomial")
lambda.min <- mod$lambda.min
 
 
test_x <- x %>%
  filter(year == 2016)
 
test_y <- test_x$year_ahead
 
test_x <- test_x %>%
  dplyr::select(-c(year, year_ahead, cluster))
 
 
yhat <- predict(mod, newx = as.matrix(test_x),
                      s = lambda.min,
                      type = "response")
 
pred <- yhat %>% tibble() %>% rename(pred = ".")
 
index = min(pred)
 
best_cutoff <- 0
best_accuracy <- 0
 
while (index < 2)
{
  cutoff <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > index, 1, 0))
 
  accuracy <- mean(cutoff$pred == test_y)
 
  if (accuracy > best_accuracy){
    best_cutoff <- index
    best_accuracy <- accuracy
  }
 
  index = index + 0.01
}
 
comparison <- pred %>%
  rowwise() %>%
  mutate(pred = ifelse(pred > 0.99, 1, 0))
 
comparison$actual <- test_y
 
mean(comparison$actual == comparison$pred)
```
